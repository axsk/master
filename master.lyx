#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass amsart
\begin_preamble
\DeclareMathOperator{\Ima}{Im}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 1
\bibtex_command default
\index_command default
\paperfontsize default
\spacing other 1.5
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip smallskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Nonparametric prior estimation from cohort data and its application to Systems
 Biology
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
This thesis will cover the development and application of an empirical Bayes
 method to the problem of parameter estimation in systems biology.
 The goal is to provide a general and practical solution to the inverse
 problem in the case of high dimensional parameter spaces and uncertain
 data.
 
\end_layout

\begin_layout Standard
Regarding it's application to systems biology or medicine a quantification
 of uncertainty of the results is of utmost importance to any practitioner
 facing decisions such as whether to apply a specific treatment or release
 a new drug.
\end_layout

\begin_layout Standard
Although the classical frequentist approach to statistics offers tools answers
 to this in terms of confidence intervals and hypothesis tests, these techniques
, aiming for point estimates, have a hard time dealing with ill-posed problems
 incorporating uncertainties and unidentifiabilities, often appearing in
 applications with large nonlinear models.
\end_layout

\begin_layout Standard
We will henceforth adopt the Bayesian view which naturally confines the
 treatment of uncertainty by its description in terms of distributions (in
 contrast to the point estimates in the frequentist approach).
\end_layout

\begin_layout Standard
As we will see it also allows for a natural incorporation of data, a circumstanc
e of ever greater importance in a time of progressing digitalization of
 our lives, the medicine and the sciences coining the term big data.
\end_layout

\begin_layout Standard
We will furthermore tackle one of the main points of criticism on the Bayesian
 approach, namely its subjectivity in the choice of the prior: Two scientists,
 given the same data and working with the same model, can come up with different
 results (the posterior) imposing different a priori knowledge about the
 parameters in questions (the prior).
\end_layout

\begin_layout Standard
This critique lead to the school of objective Bayes methods
\end_layout

\begin_layout Standard
One approach was the choice of so called 
\emph on
non-informative priors
\emph default
, designed to incorporate namely the 
\emph on
Jeffrey's prior
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "jeffreys1946invariant"

\end_inset

 and it's generalization to higher dimensions, the
\emph on
 reference priors
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "bernardo1979reference"

\end_inset

.
\end_layout

\begin_layout Standard
Another approach is given by the empirical Bayes methods:
\end_layout

\begin_layout Quote
The empirical Bayes approach to statistical decision problems is applicable
 when the same decision problem presents itself repeatedly and independently
 with a fixed but unknown a priori distribution of the parameter - Herbert
 Robbins 
\begin_inset CommandInset citation
LatexCommand cite
key "robbins1964empirical"

\end_inset

.
\end_layout

\begin_layout Standard
Here repeated measurements of the population in question, called cohort
 data, are used to construct a prior representing that population.
 The first major contribution was by Robbins
\begin_inset CommandInset citation
LatexCommand cite
key "robbins1956"

\end_inset

, suggesting the nonparametric maximization of the marginal likelihood but
 the topic got largely neglected, probably due to its computational cost,
 until the topic was brought back to attention in parametric case by Efron
 and Morris 
\begin_inset CommandInset citation
LatexCommand cite
key "efron1973stein"

\end_inset

 in 1973.
\end_layout

\begin_layout Standard
Unfortunately the pure nonparametric approach applied to finite data results
 in irregular priors, consisting of finitely many peaks.
\end_layout

\begin_layout Standard
Section 3 will therefore discuss its regularization based on similar information
 theoretic considerations as for the reference priors.
 
\end_layout

\begin_layout Standard
We then end up with a nonparametric, hence generally applicable, method
 combining the assumptions of least information with already measured informatio
n from the cohort data and therefore getting the best of both worlds.
 The suggested prior can as well be seen as a generalization of the reference
 priors to the cohort data regime.
\end_layout

\begin_layout Standard
We will also compare this method to the DS-MLE estimate by Seo and Lindsay
 
\begin_inset CommandInset citation
LatexCommand cite
key "seo2013universally"

\end_inset

.
\end_layout

\begin_layout Standard
In section 4 we will then introduce the discretization and calculation schemes.
 We will work with an importance sampling scheme and derive the necessary
 Monte Carlo approximations for the optimization problem.
\end_layout

\begin_layout Standard
As a proof of concept we will we will apply the developed methods and algorithms
 to a high-dimensional model from systems biology and discuss the results
 in section 5.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
todos:
\end_layout

\begin_layout Plain Layout
check p/
\begin_inset Formula $\rho$
\end_inset


\end_layout

\begin_layout Plain Layout
check rand.
 variable vs realization vs density
\end_layout

\end_inset


\end_layout

\begin_layout Section
Empirical Bayes Methods
\end_layout

\begin_layout Subsection
The Bayesian formalism
\end_layout

\begin_layout Standard
We start by laying out the basic formal tools in the Bayesian setting.
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 denote continuous random variables and 
\begin_inset Formula $\rho_{X,Y}\left(x,y\right)$
\end_inset

 their joint probability density.
 The 
\emph on
conditional probability
\emph default
 density of 
\begin_inset Formula $Y$
\end_inset

 given the value 
\begin_inset Formula $x$
\end_inset

 for 
\begin_inset Formula $X$
\end_inset

 is
\begin_inset Formula 
\[
\rho_{Y\mid X}\left(y|x\right):=\frac{\rho_{X,Y}\left(x,y\right)}{\rho_{X}\left(x\right)},
\]

\end_inset

where 
\begin_inset Formula $\rho_{X}\left(x\right)$
\end_inset

 is the 
\emph on
marginal density
\emph default
 of 
\begin_inset Formula $X$
\end_inset

 defined as the joint density 
\begin_inset Formula $\rho\left(x,y\right)$
\end_inset

 marginalized over all possible 
\begin_inset Formula $y$
\end_inset

:
\begin_inset Formula 
\[
\rho_{X}\left(x\right):=\int_{y}\rho\left(x,y\right)\mathrm{d}y.
\]

\end_inset


\end_layout

\begin_layout Definition
Succesive insertion of these identities leads to 
\emph on
Bayes' theorem
\emph default
 in its probability density form:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{equation}
\rho_{X,Y}\left(x|y\right):=\frac{\rho_{X,Y}\left(x,y\right)}{\rho_{Y}\left(y\right)}=\frac{\rho_{Y\mid X}\left(y|x\right)\rho_{X}\left(x\right)}{\rho_{Y}\left(y\right)}=\frac{\rho_{Y\mid X}\left(y|x\right)\rho_{X}\left(x\right)}{\int_{x}\rho_{Y\mid X}\left(y|x'\right)\rho_{X}\left(x'\right)\mathrm{d}x'}.\label{eq:bayes}
\end{equation}

\end_inset

This formula, constituting the heart of Bayesian statistics, tells us how
 to reconstruct the 
\emph on
posterior distribution
\emph default
 
\begin_inset Formula $\rho_{X\mid Y}\left(x|y\right)$
\end_inset

 of the unknown parameter 
\begin_inset Formula $X$
\end_inset

 given data 
\begin_inset Formula $Y$
\end_inset

, using the 
\emph on
likelihood
\emph default
 
\begin_inset Formula $\rho_{Y\mid X}\left(y|x\right)$
\end_inset

 of 
\begin_inset Formula $X$
\end_inset

 given 
\begin_inset Formula $Y$
\end_inset

 as well as the 
\emph on
prior
\emph default
 
\begin_inset Formula $\rho_{X}\left(x\right)$
\end_inset

 reflecting our prior assumptions on the density of 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_layout Standard
Note that for fixed 
\begin_inset Formula $y$
\end_inset

 the prior 
\begin_inset Formula $\rho_{X}\left(x\right)$
\end_inset

 and posterior 
\begin_inset Formula $\rho_{X|Y}\left(x|y\right)$
\end_inset

 both are probability densities in 
\begin_inset Formula $x$
\end_inset

, whilst the likelihood 
\begin_inset Formula $\rho_{Y\mid X}\left(y|x\right)$
\end_inset

 would be in 
\begin_inset Formula $y$
\end_inset

 but is not in 
\begin_inset Formula $x$
\end_inset

, which is why it is often called the 
\emph on
likelihood function 
\begin_inset Formula $L\left(x\mid y\right)$
\end_inset


\emph default
 for emphasis.
\end_layout

\begin_layout Standard
Also note that the denominator, the 
\emph on
evidence,
\emph default
 does not depend on 
\begin_inset Formula $x$
\end_inset

 and thus is merely a scaling constant, preserving the probability density
 property of having measure one.
 This will come in handy later for Markov Chain Monte Carlo sampling, since
 we will be able to omit it in crucial calculations.
\end_layout

\begin_layout Subsection
The likelihood model
\end_layout

\begin_layout Standard
Our inference bases on the combination of a deterministic physical model,
 our description of the reality, with a stochastic measurement error and
 the formalism of Bayes'.
 The physical model is represented as a map 
\begin_inset Formula $\Phi:\mathcal{X}\subseteq\mathbb{R}^{n}\rightarrow\mathcal{Y}\subseteq\mathbb{R}^{m}$
\end_inset

, mapping some parameter 
\begin_inset Formula $x\in\mathcal{X}$
\end_inset

 to a resulting state 
\begin_inset Formula $y\in\mathcal{Y}$
\end_inset

.
 We furthermore model the the data generating measurement process 
\begin_inset Formula $Z$
\end_inset

 as an independent Gaussian perturbation with prescribed covariance 
\begin_inset Formula $\Sigma$
\end_inset

 of that state:
\begin_inset Formula 
\begin{equation}
\rho_{Z\mid X}\left(z\mid x\right)=\Phi\left(x\right)+E,\quad E\overset{indep.}{\sim}\mathcal{N}\left(0,\Sigma\right)\label{eq:gaussmodel}
\end{equation}

\end_inset

or shorthand
\begin_inset Formula 
\[
Z\mid X\sim\mathcal{N}\left(\Phi\left(X\right),\Sigma\right),
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\mathcal{\mathcal{N}}\left(y,\,\Sigma\right)$
\end_inset

 denotes the Normal distribution with mean 
\begin_inset Formula $y$
\end_inset

 and covariance matrix 
\begin_inset Formula $\Sigma$
\end_inset

.
\end_layout

\begin_layout Standard
This 
\emph on
likelihood model 
\emph default
gives us the means to compute the probabilty of measuring a single measurement
 
\begin_inset Formula $z$
\end_inset

, given the underlying parameter 
\begin_inset Formula $x.$
\end_inset


\end_layout

\begin_layout Standard
Assuming the 
\emph on
prior distribution
\emph default
 
\begin_inset Formula $X$
\end_inset

 was known, this would enable us to compute the 
\emph on
posterior 
\begin_inset Formula $X(x|z)$
\end_inset

 
\emph default
given some measurement 
\begin_inset Formula $z$
\end_inset

 by straightforward application of the Bayes' theorem 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:bayes"

\end_inset

.
\end_layout

\begin_layout Standard
Note also that whilst this model is extensible to multiple measurements
 using the product of likelihoods as likelihood, this is only valid under
 the assumption of identically distributed likelihoods, which corresponds
 to the assumption that the same parameter 
\begin_inset Formula $x$
\end_inset

 is underlying the different measurements.
 This would be the right model if all measurements result from the same
 realization of 
\begin_inset Formula $X$
\end_inset

 (the same subject), but is wrong assuming different measurements correspond
 to independent draws from the prior 
\begin_inset Formula $X$
\end_inset

 (multiple subjects).
\end_layout

\begin_layout Subsection
The empirical Bayes model
\end_layout

\begin_layout Standard
Since in general the 
\emph on
prior 
\emph default

\begin_inset Formula $X$
\end_inset

 cannot be assumed to be known a number of different methods have been establish
ed for estimating this prior based on empirical cohort data, giving rise
 to the so called 
\emph on
empirical Bayes methods.
 
\emph default
In that context we extend the model by conditioning the prior 
\begin_inset Formula $\rho_{X}$
\end_inset

 on a hyperparater 
\begin_inset Formula $\Pi$
\end_inset

, the prior of priors if one likes, resulting in the hierarchical model
 
\begin_inset Formula $\Pi\rightarrow X\rightarrow Z$
\end_inset

, which we will refer to as the 
\emph on
hyperparametric model
\emph default
.
 
\end_layout

\begin_layout Standard
Most literature confines itself to (finite dimensional) parametric empirical
 Bayes methods, characterized by considering parametrized families of distributi
ons for the priors, e.g.
 
\begin_inset Formula 
\[
\rho_{X|\pi}=\mathcal{N}\left(\pi,\,I\right),\,\pi\in\text{Im}\left(\Pi\right)=\mathbb{R}^{n},
\]

\end_inset


\end_layout

\begin_layout Standard
since these may admit explicit formulas for prior point estimates if the
 likelihood model and prior families admit simple forms, as well as these
 usually regularization issues.
 We aim at a more general solution to the inference problem by allowing
 arbitrary distributions as priors, i.e.
 
\begin_inset Formula 
\[
\rho_{X\mid\pi}=\pi,\,\pi\in\text{Im}\left(\Pi\right)=\mathcal{M}_{1}\left(\mathcal{X}\right):=\left\{ \rho\in L^{1}\left(\mathcal{X}\right)\mid\rho\ge0,\,\left\Vert \rho\right\Vert _{L^{1}}=1\right\} ,
\]

\end_inset

resulting in a 
\emph on
nonparametric empirical Bayes 
\emph default
method.
\end_layout

\begin_layout Standard
The marginal likelihood of a prior 
\begin_inset Formula $\Pi=\pi$
\end_inset

 given a single measurement 
\begin_inset Formula $z$
\end_inset

 is then given by 
\begin_inset Formula 
\[
L\left(\pi\mid z\right)=\rho_{Z\mid\pi}\left(z\right)=\int_{\mathcal{X}}\rho_{Z\mid x}\left(z\right)\pi\left(x\right)\mathrm{d}x.
\]

\end_inset


\end_layout

\begin_layout Standard
Since this likelihood, in contrast to the basic Bayesian model above, does
 not depend on a specific realization of the latent variable 
\begin_inset Formula $X$
\end_inset

 anymore, this allows us to handle multiple measurements coming from independent
 samples of 
\begin_inset Formula $X$
\end_inset

 correctly using the product distribution:
\end_layout

\begin_layout Definition
For finite data/measurements 
\begin_inset Formula $\bm{z}^{M}=\left(z_{m}\in\mathcal{Z}\right)_{m=1,...,M}$
\end_inset

 we define the likelihood of a prior 
\begin_inset Formula $\pi$
\end_inset

 as
\begin_inset Formula 
\[
\rho\left(\bm{z}^{M}|\pi\right):=\prod_{m=1}^{M}\rho_{Z\mid\pi}\left(z_{m}\right)
\]

\end_inset


\end_layout

\begin_layout Definition
or alternatively in its renomalized logarithmic form as 
\emph on
finite data log-likelihood 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
name: log-likelihood?
\end_layout

\end_inset


\emph default

\begin_inset Formula 
\[
\mathcal{L}\left(\pi\mid\bm{z}^{M}\right):=\frac{1}{M}\log\rho\left(\bm{z}^{M}|\pi\right)=\frac{1}{M}\sum_{m=1}^{M}\log\rho_{Z\mid\pi}\left(z_{m}\right).
\]

\end_inset


\end_layout

\begin_layout Definition
For 
\begin_inset Quotes eld
\end_inset

infinite data/measurements
\begin_inset Quotes erd
\end_inset

, represented in the form of a data-generating probabilty distribution 
\begin_inset Formula $p_{Z}$
\end_inset

, we define the corresponding 
\emph on
infinite data log-likelihood 
\end_layout

\begin_layout Standard

\emph on
\begin_inset Formula 
\[
\mathcal{L}^{\infty}\left(\pi\mid\rho_{Z}\right):=\int_{\mathcal{Z}}\rho_{Z}\left(z\right)\log\rho_{Z\mid\pi}\left(z\right)\mathrm{d}z.
\]

\end_inset


\end_layout

\begin_layout Standard
The latter definition follows from the former in the limit for 
\begin_inset Formula $m\rightarrow\infty$
\end_inset

 assuming that 
\begin_inset Formula $p_{Z}$
\end_inset

 is indeed the data generating distribution:
\begin_inset Formula 
\begin{equation}
z_{m}\overset{i.i.d.}{\sim}\rho_{Z}\Rightarrow\mathcal{L}\left(\pi\mid\bm{z}^{M}\right)\overset{\text{p}}{\underset{M\rightarrow\infty}{\longrightarrow}}\mathcal{L}^{\infty}\left(\pi\mid\rho_{Z}\right).\label{eq:limit}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The following proposition demonstrates how we can recover the data underlying
 
\begin_inset Quotes eld
\end_inset

true prior
\begin_inset Quotes erd
\end_inset

 
\begin_inset Formula $\pi^{*}$
\end_inset

 in the infinite data regime by maximizing the corresponding likelihood
 functional 
\begin_inset Formula $L^{\infty}.$
\end_inset


\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:identifiable"

\end_inset

Let the hyperparametric model be 
\emph on
well specified
\emph default
, i.e.
 
\begin_inset Formula 
\[
\exists\pi^{*}\in\mathcal{M}_{1}\left(\mathcal{X}\right):\,\rho_{Z}=\rho_{Z\mid\pi^{*}}
\]

\end_inset

and 
\emph on
identifiable
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
after "chapter 5"
key "van2000asymptotic"

\end_inset


\begin_inset Formula 
\[
\rho_{Z\mid\pi^{'}}=\rho_{Z\mid\pi^{*}}\Rightarrow\pi'=\pi^{*}\quad\forall\pi'\in\mathcal{M}_{1}.
\]

\end_inset

We then have that
\begin_inset Formula 
\[
\pi^{*}=\underset{\pi'\in\mathcal{M}_{1}\left(\mathcal{X}\right)}{\arg\max}L^{\infty}\left(\pi'\right).
\]

\end_inset


\end_layout

\begin_layout Proof
Gibbs' inequality says that
\begin_inset Formula 
\[
\int_{\mathcal{Z}}\rho_{Z}\left(z\right)\log\rho_{Z}\left(z\right)\mathrm{d}z\ge\int_{\mathcal{Z}}\rho_{Z}\left(z\right)\log q\left(z\right)\mathrm{d}z
\]

\end_inset

for any probability density 
\begin_inset Formula $q$
\end_inset

, with equality if and only if 
\begin_inset Formula $q=\rho_{Z}$
\end_inset

.
 The rest follows from the assumptions.
\end_layout

\begin_layout Standard
Both of the assumptions arise nather naturally; if the model is not well
 specified this merely means the measured data 
\begin_inset Formula $\rho_{Z}$
\end_inset

 cannot be explained by any prior, thus resulting in an ill-posed problem.
 If on the other hand the model is not identifiable, which by definition
 corresponds to the injectivity of the marginal likelihood function 
\begin_inset Formula $\rho_{Z}$
\end_inset

, there exists another 
\begin_inset Formula $\pi'\ne\pi^{*}$
\end_inset

 inducing the same measurements so we cannot hope to recover the right prior
 candidate from the data.
\end_layout

\begin_layout Standard
This can be retracted though by lifting the inference problem to equivalence
 classes of priors leading to the same measurements,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\pi\sim\pi':\iff\left\Vert \rho_{Z\mid\pi}-\rho_{Z\mid\pi'}\right\Vert _{L^{1}\left(\mathcal{Z}\right)}=0,\label{eq:equiv}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
which is all we can hope for.
\end_layout

\begin_layout Standard
In practice though usually only finite data is available, and even though
 the limiting property 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:limit"

\end_inset

 might give hope that maximization of 
\begin_inset Formula $\mathcal{L}$
\end_inset

 might approximate 
\begin_inset Formula $\pi^{*}$
\end_inset

 properly, one can prove 
\begin_inset CommandInset citation
LatexCommand cite
after "Theorem 21"
key "lindsay1995mixture"

\end_inset

 that the maximizer of 
\begin_inset Formula $\mathcal{L}$
\end_inset

 is a discrete distribution with at most 
\begin_inset Formula $M$
\end_inset

 nodes.
\end_layout

\begin_layout Standard
In the field of machine learning this phenomenon, commonly occurring for
 insufficient data, is referred to as 
\emph on
overfitting
\emph default
 and usually approached by regularization techniques, methods to enforce
 more regular and smooth solutions.
\end_layout

\begin_layout Section
Regularization
\end_layout

\begin_layout Standard
To address this problem of irregularity we will introduce two regularization
 methods, the 
\emph on
maximum penalized likelihood estimation
\emph default
 (MPLE), introducing a penalization term to the former optimization problem,
 and the 
\emph on
doubly smoothed maximum likelihood estimation 
\emph default
(DSMLE), lifting the problem from the finite to the infinite data regime
 by smoothing the measurements and thus approximating the continuous data-genera
ting distribution 
\begin_inset Formula $\rho_{Z}.$
\end_inset


\end_layout

\begin_layout Subsection
Regularization via a penalization term
\end_layout

\begin_layout Standard
For a given likelihood function 
\begin_inset Formula $L$
\end_inset

 
\begin_inset Note Note
status open

\begin_layout Plain Layout
specify
\end_layout

\end_inset

 and a 
\emph on
roughness penalty 
\emph default
(or 
\emph on
regularization term
\emph default
) 
\begin_inset Formula $\Phi:\mathcal{M}_{1}\rightarrow\mathbb{R}$
\end_inset

, responsible for penalizing unsmooth or unwanted solutions with high values,
 the MPLE 
\begin_inset Formula $\pi_{\Phi}$
\end_inset

 estimate admits the form 
\begin_inset Formula 
\begin{equation}
\pi_{\Phi}=\underset{\pi}{\arg\max}\log L\left(\pi\right)-\Phi\left(\pi\right).\label{eq:mple}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
This approach also allows for an interpretation in the context of the Bayesian
 hyperparametric model by identifying the penalty 
\begin_inset Formula $\Phi$
\end_inset

 with the hyperprior 
\begin_inset Formula $\Pi$
\end_inset

 via 
\begin_inset Formula $\rho_{\Pi}\propto e^{-\Phi}$
\end_inset

.
 The posterior then is
\begin_inset Formula 
\[
\rho_{\Pi\mid Z}\propto L\left(\pi\right)e^{-\Phi\left(\pi\right)}
\]

\end_inset

and thus the 
\emph on
maximum a posteriori 
\emph default
estimate 
\begin_inset Formula $\pi_{MAP}$
\end_inset

 for the hyperparametric model corresponds to the MPLE estimate:
\begin_inset Formula 
\[
\pi_{MAP}=\underset{\pi}{\arg\max}L\left(\pi\right)e^{-\Phi\left(\pi\right)}=\underset{\pi}{\arg\max}\log L\left(\pi\right)-\Phi\left(\pi\right)=\pi_{\Phi}.
\]

\end_inset


\end_layout

\begin_layout Standard
One now might might argue that we started with the question of finding the
 correct prior and just complicated the situation by transferring this problem
 to the question of the correct hyperprior.
 While this may be true we argue that the latter can be tackled from a rather
 abstract, problem independent standpoint, hence leading to a more general
 answer.
\end_layout

\begin_layout Subsection
Choice of the penalty
\end_layout

\begin_layout Standard
Many of the common penalty functions currently in use, penalizing either
 large amplitudes (e.g.
 ridge regression 
\begin_inset CommandInset citation
LatexCommand cite
after "section 1.6"
key "mclachlan2007algorithm"

\end_inset

) or derivatives (c.f.
 
\begin_inset CommandInset citation
LatexCommand cite
key "good1971nonparametric"

\end_inset

) of the prior, are not invariant under reparametrizations of the parameter
 space 
\begin_inset Formula $\mathcal{X}$
\end_inset

 and are rather ad-hoc without a natural derivation.
 Following a more information-theoretic view Good 
\begin_inset CommandInset citation
LatexCommand cite
key "good1963maximum"

\end_inset

 suggested the use of the differential entropy for the penalty
\begin_inset Formula 
\[
\Phi_{H_{X}}\left(\pi\right):=\gamma\int_{\mathcal{X}}\rho_{X\mid\pi}\left(x\right)\log\rho_{X\mid\pi}\left(x\right)\mathrm{d}x,
\]

\end_inset

 with 
\begin_inset Formula $\gamma\in\mathbb{R}^{+}$
\end_inset

 being a parameter determining the degree of smoothing due to this penalty.
 This prior however is still variant under reparametrizations of 
\begin_inset Formula $\mathcal{X}$
\end_inset

 due to the log-nonlinearity.
 This means that if two scientists estimate the prior using equivalent models,
 e.g.
 by using different systems of units, they would end up with different estimates.
 Hence this penalty does not rectify the problem of subjectivity in the
 Bayesian method.
 We therefore look for a penalty which is invariant under coordinate transformat
ions.
\end_layout

\begin_layout Standard
Embracing the information theoretic approach we therefore propose the use
 of the 
\emph on
mutual information 
\emph default
instead of the entropy for the penalty:
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $A:\,\Omega\rightarrow\mathcal{A}$
\end_inset

 and 
\begin_inset Formula $B:\,\Omega\rightarrow\mathcal{B}$
\end_inset

 be two continuous random variables, 
\begin_inset Formula $\rho_{A,B}$
\end_inset

 their joint probability density and 
\begin_inset Formula $\rho_{A},\,\rho_{B}$
\end_inset

 their respective marginal densities.
 Their mutual information is defined as
\begin_inset Formula 
\begin{align*}
\mathcal{I}\left(A;B\right): & =\int_{\mathcal{A}}\int_{\mathcal{B}}\rho_{A,B}\left(a,b\right)\log\left(\frac{\rho_{A,B}\left(a,b\right)}{\rho_{A}\left(a\right)\rho_{B}\left(b\right)}\right)\mathrm{d}a\mathrm{d}b\\
 & =\mathbb{E}_{b\sim B}\left[D_{KL}\left(\rho_{A\mid b}\parallel\rho_{A}\right)\right]\\
 & =H\left(B\right)-H\left(B;A\right),
\end{align*}

\end_inset

with 
\begin_inset Formula $D_{KL}$
\end_inset

 being the 
\emph on
Kullback-Leibler divergence 
\emph default
from 
\begin_inset Formula $\rho_{A}$
\end_inset

 to 
\begin_inset Formula $\rho_{A\mid b}$
\end_inset

 
\begin_inset Formula 
\[
D_{KL}\left(\rho_{A\mid b}\parallel\rho_{A}\right):=\int_{\mathcal{A}}\rho_{A\mid b}\left(a\right)\log\frac{\rho_{A\mid b}\left(a\right)}{\rho_{A}\left(a\right)}\mathrm{d}a,
\]

\end_inset


\end_layout

\begin_layout Definition
and 
\begin_inset Formula $H\left(B\right)$
\end_inset

, 
\series bold

\begin_inset Formula $H\left(B;A\right)$
\end_inset

 
\series default
being the 
\emph on
differential entropy
\emph default
 of 
\begin_inset Formula $B$
\end_inset

 respectively the 
\emph on
conditional differential
\emph default
 entropy of 
\begin_inset Formula $B$
\end_inset

 given 
\begin_inset Formula $A$
\end_inset

 
\begin_inset Formula 
\begin{eqnarray*}
H\left(B\right) & := & -\int_{\mathcal{B}}\rho_{B}\left(b\right)\log\left(\rho_{B}\right)\mathrm{d}b\\
H\left(B;A\right) & := & \int_{\mathcal{A}}\rho_{A}\left(a\right)H\left(B\mid a\right)\mathrm{d}a\\
 & = & -\int_{\mathcal{A}}\rho_{A}\left(a\right)\int_{\mathcal{B}}\rho_{B\mid a}\left(b\right)\log\left(\rho_{B\mid a}\right)\mathrm{d}b\mathrm{d}a.
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
The mutual information quantifies the 
\begin_inset Quotes eld
\end_inset

amount of information
\begin_inset Quotes erd
\end_inset

 that one random variable shares with the respective other, expressed by
 the information content of the their joint distribution (
\begin_inset Formula $\rho_{A,B}$
\end_inset

) relative to their joint distribution if they were independent (
\begin_inset Formula $\rho_{A}\rho_{B})$
\end_inset

, weighted by their joint distribution.
\end_layout

\begin_layout Standard
We can gain further insights into its meaning by expressing it in terms
 of another fundamental information-theoretic quantity, the Kullback-Leibler
 divergence 
\begin_inset Formula $D_{KL}\left(A\parallel B\right)$
\end_inset

 from 
\begin_inset Formula $B$
\end_inset

 to 
\begin_inset Formula $A$
\end_inset

 (also called 
\emph on
information gain 
\emph default
or 
\emph on
relative entropy
\emph default
).
 It is a measure for the loss of information when considering 
\begin_inset Formula $B$
\end_inset

 as a approximation to 
\begin_inset Formula $A$
\end_inset

, or consequently in the Bayesian context it is the gain of information
 revising one's beliefs from the prior 
\begin_inset Formula $B$
\end_inset

 to the posterior 
\begin_inset Formula $A$
\end_inset

.
\end_layout

\begin_layout Standard
In this form the mutual information of 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 corresponds to the expected information gain from the prior to the posterior
 over 
\begin_inset Formula $A$
\end_inset

 when the measurements are 
\begin_inset Formula $B$
\end_inset

-distributed.
 This interpretation gives rise to the following definition:
\end_layout

\begin_layout Definition
For 
\begin_inset Formula $\gamma>0$
\end_inset

 constant we define the
\emph on
 information penalty
\emph default
 
\begin_inset Formula 
\begin{eqnarray}
\Phi_{I}\left(\pi\right): & = & -\gamma\mathcal{I}\left(X\mid\pi;Z\mid\pi\right)\nonumber \\
 & = & -\gamma\int_{\mathcal{X}}\rho_{X\mid\pi}\left(x\right)\int_{\mathcal{Z}}\rho_{Z\mid x}\left(z\right)\log\left(\frac{\rho_{Z\mid x}\left(z\right)}{\rho_{Z\mid\pi}\left(z\right)}\right)\mathrm{d}z\mathrm{dx}.\label{eq:ipen}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
Minimizing this penalty then corresponds to maximizing the amount of shared
 information between the prior-predictive distribution 
\begin_inset Formula $Z\mid\pi$
\end_inset

 and the prior 
\begin_inset Formula $X\mid\pi$
\end_inset

 itself (where we understand these random variables as restrictions of 
\begin_inset Formula $Z$
\end_inset

 respectively 
\begin_inset Formula $X$
\end_inset

 onto the events where 
\begin_inset Formula $\Pi=\pi$
\end_inset

).
 In terms of the Kullback-Leibler formulation this means priors 
\begin_inset Formula $\pi$
\end_inset

 are rewarded by the amount of information gain expected from their induced
 measurements hence encoding a notion of non-informativity.
\end_layout

\begin_layout Standard
Fortunately the mutual information is also transformation invariant, thus
 allowing for the application of the information penalty independent of
 the models parametrization:
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lem:invariance"

\end_inset

Let 
\begin_inset Formula $A$
\end_inset

, 
\begin_inset Formula $B$
\end_inset

 as above, and 
\begin_inset Formula $\varphi^{-1}:\,\mathcal{A}\rightarrow\tilde{\mathcal{A}}$
\end_inset

, 
\begin_inset Formula $\psi^{-1}:\,\mathcal{B}\rightarrow\tilde{\mathcal{B}}$
\end_inset

 be diffeomorphisms defining the coordinate transformations and corresponding
 transformed random variables 
\begin_inset Formula $\tilde{A},\,\tilde{B}$
\end_inset

 with the densities
\begin_inset Formula 
\[
\rho_{\tilde{A},\tilde{B}}\left(\tilde{a},\tilde{b}\right):=\rho_{A,B}\left(\varphi\left(\tilde{a}\right),\psi\left(\tilde{b}\right)\right)\left|D\varphi\left(\tilde{a}\right)\right|\left|D\psi\left(\tilde{b}\right)\right|
\]

\end_inset


\begin_inset Formula 
\[
\rho_{\tilde{A}}\left(\tilde{a}\right):=\rho_{A}\left(\varphi\left(\tilde{a}\right)\right)\left|D\varphi\left(\tilde{a}\right)\right|,\,\quad\rho_{\tilde{B}}\left(\tilde{b}\right):=\rho_{B}\left(\psi\left(\tilde{b}\right)\right)\left|D\psi\left(\tilde{b}\right)\right|.
\]

\end_inset


\end_layout

\begin_layout Lemma
The mutual information 
\begin_inset Formula $\mathcal{I}\left(A;B\right)$
\end_inset

 is then invariant under these coordinate transformations of 
\begin_inset Formula $\mathcal{A}$
\end_inset

 and 
\begin_inset Formula $\mathcal{B}$
\end_inset

:
\begin_inset Formula 
\[
\mathcal{I}\left(A;B\right)=\mathcal{I}(\tilde{A};\tilde{B}).
\]

\end_inset


\end_layout

\begin_layout Proof
According to the change of variables formula 
\begin_inset Formula 
\begin{align*}
 & \ \mathcal{I}\left(A;B\right)\\
= & \int_{\mathcal{B}}\int_{\mathcal{A}}\rho_{A,B}\left(a,b\right)\log\left(\frac{\rho_{A,B}\left(a,b\right)}{\rho_{A}\left(a\right)\rho_{B}\left(b\right)}\right)\mathrm{d}a\mathrm{d}b.\\
= & \int_{\mathcal{\tilde{B}}}\int_{\tilde{A}}\rho_{A,B}\left(\varphi\left(\tilde{a}\right),\psi\left(\tilde{b}\right)\right)\log\left(\frac{\rho_{A,B}\left(\varphi\left(\tilde{a}\right),\psi\left(\tilde{b}\right)\right)}{\rho_{A}\left(\varphi\left(\tilde{a}\right)\right)\rho_{B}\left(\psi\left(\tilde{b}\right)\right)}\right)\left|D\varphi\left(\tilde{a}\right)\right|\left|D\psi\left(\tilde{b}\right)\right|\mathrm{d}\tilde{a}\mathrm{d}\tilde{b}\\
= & \int_{\mathcal{\tilde{B}}}\int_{\tilde{A}}\rho_{\tilde{A},\tilde{B}}\left(\tilde{a},\tilde{b}\right)\log\left(\frac{\rho_{\tilde{A},\tilde{B}}\left(\tilde{a},\tilde{b}\right)}{\rho_{\tilde{A}}\left(\tilde{a}\right)\rho_{\tilde{B}}\left(\tilde{b}\right)}\right)\mathrm{d}\tilde{a}\mathrm{d}\tilde{b}\\
= & \ \mathcal{I}(\tilde{A};\tilde{B})
\end{align*}

\end_inset


\end_layout

\begin_layout Corollary
The maximum penalized likelihood estimator 
\begin_inset Formula $\pi_{MPLE}$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:mple"

\end_inset

 with the information penalty 
\begin_inset Formula $\Phi_{I}$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ipen"

\end_inset

 is invariant under transformations of 
\begin_inset Formula $\mathcal{X}$
\end_inset

 and 
\begin_inset Formula $\mathcal{Y}$
\end_inset

 as in 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:invariance"

\end_inset

.
\end_layout

\begin_layout Standard
In the case of an additive measurement error we can simplify the MPLE estimator
 by only computing the entropy of the prior predictive distribution:
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:addmeastheo"

\end_inset

For models with additive measurement error 
\begin_inset Formula $E\sim\rho_{E}$
\end_inset


\begin_inset Formula 
\[
Z=G\left(X\right)+E
\]

\end_inset

the MPLE estimate 
\begin_inset Formula $\pi_{\Phi_{H_{Z}}}$
\end_inset

, penalized by the 
\emph on
Z-entropy
\emph default

\begin_inset Formula 
\[
\Phi_{H_{Z}}\left(\pi\right):=-\gamma H\left(Z\mid\pi\right),
\]

\end_inset

 and the information penalty coincide:
\begin_inset Formula 
\[
\pi_{\Phi_{I}}=\pi_{\Phi_{E_{Z}}}.
\]

\end_inset


\end_layout

\begin_layout Proof
In the case of additive measurement error 
\begin_inset Formula $\rho_{Z\mid x}$
\end_inset

 consists of shifts of 
\begin_inset Formula $\rho_{E}$
\end_inset


\begin_inset Formula 
\[
\rho_{Z\mid x}\left(z\right)=\rho_{E}\left(z-G\left(x\right)\right)
\]

\end_inset

and thus 
\begin_inset Formula 
\begin{align*}
H\left(Z\mid x\right) & =\int_{\mathcal{Z}}\rho_{Z\mid x}\left(z\right)\log\left(\rho_{Z\mid x}\left(z\right)\right)\mathrm{d}z\\
 & =\int_{\mathcal{Z}}\rho_{E}\left(z\right)\log\left(\rho_{E}\left(z\right)\right)\mathrm{d}z\\
 & =H\left(E\right).
\end{align*}

\end_inset

Hence the conditional entropy part is constant and both penalties agree
 up to an additive constant
\begin_inset Formula 
\begin{align*}
\Phi_{I}\left(\pi\right) & =-\gamma\left(H\left(Z\mid\pi\right)-H\left(Z;X\mid\pi\right)\right)\\
 & =-\gamma\left(H\left(Z\mid\pi\right)-\int_{\mathcal{X}}\rho_{X\mid\pi}\left(x\right)H\left(Z\mid x\right)\mathrm{d}x\right)\\
 & =-\gamma H\left(Z\mid\pi\right)+H\left(E\right)\\
 & =\Phi_{H_{Z}}+H\left(E\right).
\end{align*}

\end_inset

Therefore their maxima agree and the estimates are the same.
\end_layout

\begin_layout Remark
For the mentioned additive error model and discrete parameter space 
\begin_inset Formula $\mathcal{X}$
\end_inset

, Klebanov et al.
 
\begin_inset CommandInset citation
LatexCommand cite
after "3.1"
key "theo1"

\end_inset

 show that the hyperprior 
\begin_inset Formula $\rho_{\Pi}\left(\pi\right):\propto\exp H\left(Z\mid\pi\right)$
\end_inset

 maximizes the total entropy 
\begin_inset Formula $H\left(Z,\Pi\right)$
\end_inset

 of the whole model and furthermore conjecture this to hold as well for
 continious 
\begin_inset Formula $\mathcal{X}$
\end_inset

.
 This derivation from a maximum entropy principle is a further justification
 for the choice of 
\begin_inset Formula $\Phi_{H_{Z}}$
\end_inset

 as a meaningful penalty.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Remark
In the case of no data the likelihood term of 
\begin_inset Formula $\pi_{\Phi_{I}}$
\end_inset

 vanishes.
 It then matches the definition of reference priors 
\begin_inset CommandInset citation
LatexCommand cite
key "berger2009formal"

\end_inset

 by Beger et al.
 Therefore this estimation routine can be seen as an extension of reference
 priors from a noninformative to a cohort-data based empirical Bayes approach.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Remark
It can be shown that the information penalty is convex in 
\begin_inset Formula $\pi$
\end_inset

, with strict convexity in the identifiable case.
 Together with the convexity of the likelihood function 
\begin_inset Formula $L$
\end_inset

, the MPLE 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:mple"

\end_inset

 becomes a concave optimization problem.
\end_layout

\begin_layout Subsection
Regularization by smoothing of the data
\begin_inset CommandInset label
LatexCommand label
name "subsec:dsmle"

\end_inset


\end_layout

\begin_layout Standard
Instead of relying on the coarse approximation of the data generating distributi
on by the empiricial distribution 
\begin_inset Formula $\rho_{\bm{z}^{M}}\approx\rho_{Z}$
\end_inset

 and then penalizing overconfident priors, we may as well address the issue
 of overfitting by providing a smooth approximation 
\begin_inset Formula $\rho_{Z}^{appr}$
\end_inset

 to 
\begin_inset Formula $\rho_{Z}$
\end_inset

.
\end_layout

\begin_layout Standard
Seo and Lindsay 
\begin_inset CommandInset citation
LatexCommand cite
key "seo2013universally"

\end_inset

 introduced the 
\emph on
doubly-smoothed maximum likelihood estimator 
\emph default
(DS-MLE) based on a kernel density estimate of 
\begin_inset Formula $\rho_{Z}$
\end_inset

.
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $K:\mathcal{Z}\rightarrow\mathbb{R}$
\end_inset

 be a kernel density function and 
\begin_inset Formula $z_{m}\overset{i.i.d.}{\sim}\rho_{Z},\,m=1,...,M$
\end_inset

 be 
\begin_inset Formula $M$
\end_inset

 measurements.
 The 
\emph on
smoothed data density
\emph default
 is then defined as
\begin_inset Formula 
\[
\tilde{\rho}_{\bm{z}^{M}}\left(z\right)=\left(\rho_{\bm{z}^{M}}*K\right)\left(z\right):=\frac{1}{M}\sum_{m=1}^{M}K\left(z-z_{m}\right).
\]

\end_inset

The corresponding 
\emph on
smoothed likelihood model
\emph default
 is given by
\begin_inset Formula 
\[
\tilde{\rho}_{Z\mid x}=\rho_{Z,x}*K,\,\tilde{\rho}_{Z\mid\pi}=\rho_{Z\mid\pi}*K.
\]

\end_inset

Note that when smoothing the data we also have to smooth the model (hence
 
\emph on
doubly smoothed
\emph default
) to amount for the additional uncertainty in the data and stay consistent:
\begin_inset Formula 
\[
\tilde{\rho}_{\bm{z}^{M}}\overset{M\rightarrow\infty}{\longrightarrow}\rho_{Z}*K=\tilde{\rho}_{Z\mid\pi^{*}}\ne\rho_{Z\mid\pi^{*}},
\]

\end_inset

 where 
\begin_inset Formula $\pi^{*}$
\end_inset

 is the data-generating prior as in 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:identifiable"

\end_inset

.
\end_layout

\begin_layout Definition
The resulting DS-MLE then takes the form
\begin_inset Formula 
\[
\pi_{DS}:=\underset{\pi\in\mathcal{M}_{1}\left(\mathcal{X}\right)}{\arg\max}\mathcal{L}^{\infty}\left(\pi\mid\tilde{\rho}_{\bm{z}^{M}}\right)
\]

\end_inset

 and is proved to be consistent under weak assumptions on the kernel and
 likelihood model (c.f.
 
\begin_inset CommandInset citation
LatexCommand cite
key "seo2013universally"

\end_inset

).
 
\end_layout

\begin_layout Definition
Note however that the choice of a kernel 
\begin_inset Formula $K$
\end_inset

 leaves space for debate and furthermore for fixed kernels this procedure
 is not invariant under reparametrizations of the measurement space 
\begin_inset Formula $\mathcal{Z}$
\end_inset

.
 Hence this approach, although rather natural and simple does not remedy
 the problem of subjectivity of the Bayes' method.
\end_layout

\begin_layout Section
Numerical schemes
\end_layout

\begin_layout Subsection
Monte Carlo approximations
\end_layout

\begin_layout Standard
Since the arising integrals are in general not tractable analytically, we
 will make use of sample based discretization of the continious spaces 
\begin_inset Formula $\mathcal{X}$
\end_inset

, 
\begin_inset Formula $\mathcal{Z}$
\end_inset

 and use Monte Carlo integration for the corresponding integrals.
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Enumerate
Given 
\begin_inset Formula $M$
\end_inset

 measurements 
\begin_inset Formula $\bm{z}=\left(z_{i}\right)_{i=1}^{M}$
\end_inset

 sampled across the population, these are distributed across the marginal
 measurement distribution 
\begin_inset Formula $z_{i}\sim\rho_{Z}$
\end_inset

 by construction of the model.
 We can hence approximate
\begin_inset Formula 
\[
\rho_{Z}\approx\frac{1}{\#\bm{z}}\sum_{z\in\bm{z}}\delta_{z}.
\]

\end_inset


\end_layout

\begin_layout Enumerate
In the case of the parameter space 
\begin_inset Formula $\mathcal{X}$
\end_inset

 we start with an arbitrary sampling 
\begin_inset Formula $\bm{x=}\left(x_{k}\in\mathcal{X}\right)_{k=1}^{K}$
\end_inset

 distributed according to a density 
\begin_inset Formula $x_{i}\sim\rho_{X}$
\end_inset

.
 We can now approximate any other density distribution 
\begin_inset Formula $\rho_{Y}$
\end_inset

 on 
\begin_inset Formula $\mathcal{X}$
\end_inset

 as an importance sampling with weights 
\begin_inset Formula $\bm{w}=\left(w_{k}\right)_{k=1}^{K},\quad w_{k}\ge0,\quad\sum_{k=1}^{K}w_{k}=1$
\end_inset

 such that 
\begin_inset Formula $w_{i}\propto\frac{\rho_{Y}\left(x_{i}\right)}{\rho_{X}\left(x_{i}\right)}.$
\end_inset

 We then have
\begin_inset Formula 
\[
\rho_{Y}\approx\sum_{k=1}^{K}w_{k}\delta_{x_{k}}.
\]

\end_inset


\end_layout

\begin_layout Standard
Expressing any prior 
\begin_inset Formula $\pi$
\end_inset

 in terms of its weights
\begin_inset Formula 
\[
\pi\approx\rho_{X\mid w}:=\sum_{k=1}^{K}w_{k}\delta_{x_{k}},
\]

\end_inset


\end_layout

\begin_layout Standard
the prior predictive distribution can be approximated by
\begin_inset Formula 
\[
\rho_{Z\mid\pi}\left(z\right)=\int_{\mathcal{X}}\rho_{Z\mid x}\left(z\right)\pi\left(x\right)\mathrm{d}x\approx\rho_{Z\mid w}\left(z\right):=\sum_{k=1}^{K}w_{k}\rho_{Z\mid x_{k}}\left(z\right).
\]

\end_inset


\end_layout

\begin_layout Standard
Inserting this into the marginal likelihood leads to
\begin_inset Formula 
\[
L\left(\pi\mid\bm{z}^{M}\right)\approx L\left(\bm{w}\mid\bm{z}^{M}\right):=\prod_{m=1}^{M}\sum_{k=1}^{K}w_{k}\rho_{Z\mid x_{k}}\left(z_{m}\right).
\]

\end_inset


\end_layout

\begin_layout Standard
In order to integrate over the density 
\begin_inset Formula $\rho_{Z\mid\pi}$
\end_inset

 for the entropy hyperprior, we approximate its density by an additional
 weighted sampling consisting of 
\begin_inset Formula $\bar{K}>K$
\end_inset

 
\begin_inset Formula $\mathcal{Z}$
\end_inset

-samples generated from the given 
\begin_inset Formula $\mathcal{X}$
\end_inset

-sampling by
\begin_inset Formula 
\[
\bar{\bm{z}}:=\left(\bar{z}_{j}\sim\rho_{Z\mid x_{J\left(j\right)}}\right)_{j=1}^{\bar{K}}
\]

\end_inset

with corresponding weights
\begin_inset Formula 
\[
\bar{w_{j}}:=\frac{w_{J\left(j\right)}}{\#J^{-1}\left(J\left(j\right)\right)}.
\]

\end_inset

Here 
\begin_inset Formula $J:\{1,2,...,\bar{K}\}\rightarrow\left\{ 1,2,...,K\right\} $
\end_inset

 denotes a surjective index mapping function, mapping from the 
\begin_inset Formula $\mathcal{Z}$
\end_inset

- to the corresponding 
\begin_inset Formula $\mathcal{X}$
\end_inset

-samples indices.
 The normalizing factor in the weights amounts for the inflation by multiple
 
\begin_inset Formula $\mathcal{Z}$
\end_inset

-samples 
\begin_inset Formula $\bar{z}_{i},\,\bar{z}_{j}$
\end_inset

 from a single 
\begin_inset Formula $\mathcal{X}$
\end_inset

-sample in the case of 
\begin_inset Formula $J\left(i\right)=J\left(j\right)$
\end_inset

.
\end_layout

\begin_layout Standard
The Monte Carlo approximation to the 
\begin_inset Formula $\mathcal{Z}$
\end_inset

-entropy then takes the form
\begin_inset Formula 
\begin{align*}
H\left(Z\mid\pi\right) & \approx H\left(Z\mid\bm{w}\right):=-\gamma\sum_{j=1}^{\bar{K}}\bar{w}_{j}\log\left(\sum_{k=1}^{K}w_{k}\rho_{Z\mid x_{k}}\left(\bar{z}_{j}\right)\right).
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
EM algorithm for NPMLE and DS-MLE
\end_layout

\begin_layout Standard
Equipped with these formulas we can now tackle the problem of the Maximum
 Likelihood estimation.
\end_layout

\begin_layout Standard
Herefore we introduce the 
\emph on
Expectation Maximization 
\emph default
(EM) algorithm following the classic paper of Dempster, Laird and Rubin
 
\begin_inset CommandInset citation
LatexCommand cite
key "dempster1977maximum"

\end_inset

.
\end_layout

\begin_layout Standard
We start by defining the 
\emph on
complete data likelihood function
\emph default

\begin_inset Formula 
\begin{align*}
L^{c}\left(\bm{x},\bm{z}\mid w\right): & =\prod_{m=1}^{M}\rho_{X\mid w}\left(x_{m}\right)\rho_{Z\mid w}\left(z_{m}\right)\\
 & =\prod_{m=1}^{M}w_{m}\sum_{k=1}^{K}w_{k}\rho_{Z\mid x_{k}}\left(z_{m}\right)
\end{align*}

\end_inset

the likelihood of a specific prior represented by 
\begin_inset Formula $w$
\end_inset

 given the measurements 
\begin_inset Formula $\bm{z}=\left(z_{m}\right)_{m=1}^{M}$
\end_inset

 as well as the parameters 
\begin_inset Formula $\bm{x}=\left(x_{m}\right)_{m=1}^{M}$
\end_inset

, where the completeness is meant in the context of knowing all involved
 variables, including 
\begin_inset Formula $\bm{x}$
\end_inset

.
\end_layout

\begin_layout Standard
Based on this we define the 
\emph on
expected complete data log-likelihood 
\emph default
of 
\begin_inset Formula $\pi$
\end_inset

 with respect to the estimate 
\begin_inset Formula $\pi_{n}$
\end_inset

, the expectation over the 
\begin_inset Formula $\log$
\end_inset

 of the compete data likelihood conditioned on the current estimate 
\begin_inset Formula $\pi$
\end_inset

, i.e.
\emph on

\begin_inset Formula 
\begin{align*}
Q\left(w\mid w_{n}\right): & =\mathbb{E}_{\bm{X}_{n}}\left[\log\left(L^{c}\left(\bm{X},\bm{z}\mid w\right)\right)\right],\\
 & =\mathbb{E}_{\bm{X}_{n}}\left[\sum_{m=1}^{m}\log\left(\rho_{X\mid w}\left(x_{m}\right)\rho_{Z\mid w}\left(z_{m}\right)\right)\right]\\
 & =\sum_{m=1}^{M}\mathbb{E}_{x\sim\rho_{X\mid w_{n},z_{m}}}\left[\log\left(\rho_{X\mid w}\left(x\right)\rho_{Z\mid w}\left(z_{m}\right)\right)\right]\\
 & =\sum_{m=1}^{M}\sum_{k=1}^{K}\frac{w_{n,k}\rho_{Z\mid x_{k}}\left(z_{m}\right)}{\rho_{Z\mid w_{n}}\left(z_{m}\right)}\log\left(w_{k}\rho_{Z\mid x_{k}}\left(z_{m}\right)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\bm{X}_{n}=\left(x_{m}\overset{\text{i.i.d.}}{\sim}\rho_{X\mid w_{n},z_{m}}\right)_{m=1}^{M}$
\end_inset

.
 The second step follows from the insight that after exchanging integration
 and summation each 
\begin_inset Formula $\log$
\end_inset

 term depends only on a single 
\begin_inset Formula $x_{m}$
\end_inset

 and hence the other 
\begin_inset Formula $x_{m}$
\end_inset

's get marginalized out.
\end_layout

\begin_layout Standard
The EM algorithm works by iteratively maximizing the expected complete-data
 log-likelihood under the current estimate 
\begin_inset Formula $w_{n}$
\end_inset

 over the space of admissible weightings 
\begin_inset Formula $\mathcal{W}:=w^{*}\in\mathcal{M}_{1}\left(\left\{ x_{1},...,x_{K}\right\} \right)$
\end_inset


\begin_inset Formula 
\[
w_{n+1}:=\underset{w^{*}\in\mathcal{W}}{\arg\max\,}Q\left(w^{*}\mid w_{n}\right).
\]

\end_inset


\end_layout

\begin_layout Standard
For a proof of uniqueness and convergence in the case of strict convex likelihoo
ds we refer to 
\begin_inset CommandInset citation
LatexCommand cite
key "dempster1977maximum"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand cite
key "wu1983convergence"

\end_inset

.
\end_layout

\begin_layout Standard
We now show how to explicitly compute the maximizer 
\begin_inset Formula $w^{*}$
\end_inset

:
\end_layout

\begin_layout Standard
A necessary condition is that the gradient at 
\begin_inset Formula $w^{*}$
\end_inset

 is orthogonal to the tangent space of 
\begin_inset Formula $\mathcal{W}$
\end_inset

, which means that all components of the gradient are the same:
\begin_inset Formula 
\begin{align*}
 & \frac{\mathrm{d}Q\left(w^{*}\mid w\right)}{\mathrm{d}w^{*}}\perp T_{w^{*}}\mathcal{W}\\
\Rightarrow\, & \exists c\in\mathbb{R}\:\forall k=1,...,K:\\
 & \frac{\mathrm{d}Q\left(w^{*}\mid w\right)}{\mathrm{d}w_{k}^{*}}=\sum_{m=1}^{M}\frac{w_{n,k}}{w_{k}^{*}}\frac{\rho_{Z\mid x_{k}}\left(z_{m}\right)}{\rho_{Z\mid w_{n}}\left(z_{m}\right)}=c\\
\Rightarrow\, & w_{k}^{*}=\frac{w_{n,k}}{c}\sum_{m=1}^{M}\frac{\rho_{Z\mid x_{k}}\left(z_{m}\right)}{\rho_{Z\mid w_{n}}\left(z_{m}\right)}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $\sum_{k}w_{k}^{*}=1$
\end_inset

 we conclude 
\begin_inset Formula $c=1/M$
\end_inset

 and hence end up with the explicit EM step 
\begin_inset Formula $w_{n+1}=\psi\left(w_{n}\right):$
\end_inset


\begin_inset Formula 
\[
\psi\left(w_{n}\right)_{k}:=\frac{w_{n,k}}{M}\sum_{m=1}^{M}\frac{\rho_{Z\mid x_{k}}\left(z_{m}\right)}{\rho_{Z\mid w_{n}}\left(z_{m}\right)}.
\]

\end_inset


\end_layout

\begin_layout Standard
Note that this update step corresponds to the inference of the posterior
 
\begin_inset Formula $w_{n+1}$
\end_inset

 based on the current prior 
\begin_inset Formula $w_{n}$
\end_inset

 for the model consisting of a uniform mixture of M persons with individual
 measurements 
\begin_inset Formula $z_{m}.$
\end_inset


\end_layout

\begin_layout Standard
Applying the Monte Carlo discretization to the DS-MLE setting (
\begin_inset CommandInset citation
LatexCommand cite
key "seo2013universally"

\end_inset

) we end up with the above EM-algorithm of the NPMLE applied to the augmented
 data points 
\begin_inset Formula $z_{m}\overset{i.i.d}{\sim}\tilde{\rho}_{\bm{z}^{M}}$
\end_inset

 and the smoothed likelihoods (c.f.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:dsmle"

\end_inset

).
 Since 
\begin_inset Formula $M$
\end_inset

 data points result in maximally 
\begin_inset Formula $M$
\end_inset

 peaks in the NPMLE 
\begin_inset CommandInset citation
LatexCommand cite
key "lindsay1995mixture"

\end_inset

, a necessary condition for strictly positive weights is that the number
 of augmented data points is at least that of the parameter-space nodes,
 
\begin_inset Formula $M>K.$
\end_inset

 
\end_layout

\begin_layout Subsection
Optimization for MPLE
\end_layout

\begin_layout Standard
In the case of additive the measurement error the Monte Carlo discretized
 version of the MPLE with the information penalty takes the form
\begin_inset Formula 
\begin{align*}
w_{\Phi_{I}} & =\arg\max_{\bm{w}\in\mathcal{W}}O\left(\bm{w}\right)\\
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
with objective function
\begin_inset Formula 
\begin{align*}
O\left(w\right) & =\log L\left(\bm{w}\mid\bm{z}^{M}\right)-H\left(Z\mid\bm{z}^{M}\right)\\
 & =\log\prod_{m=1}^{M}\sum_{k=1}^{K}w_{k}\rho_{Z\mid x_{k}}\left(z_{m}\right)+\gamma\sum_{j=1}^{\bar{K}}\bar{w}_{j}\log\left(\sum_{k=1}^{K}w_{k}\rho_{Z\mid x_{k}}\left(\bar{z}_{j}\right)\right).
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Being a composition of linear and concave functions the objective 
\begin_inset Formula $O$
\end_inset

 is easily shown to be concave, allowing for the use of constraint concave/conve
x optimization routines.
 
\end_layout

\begin_layout Standard
The high dimensionality of 
\begin_inset Formula $\bm{w}$
\end_inset

 suggests the usage of derivative based optimization techniques.
 The derivative of the objective is given by
\begin_inset Formula 
\begin{align*}
\frac{\mathrm{d}O}{\mathrm{d}w_{k}}\left(w\right) & =\frac{\sum_{m=1}^{M}\rho_{Z\mid x_{k}}\left(z_{m}\right)}{\prod_{m=1}^{M}\sum_{k=1}^{K}w_{k}\rho_{Z\mid x_{k}}\left(z_{m}\right)}\\
 & +\gamma\sum_{j=1}^{\bar{K}}\frac{\bar{w}_{j}\rho_{Z\mid x_{k}}\left(\bar{z}_{j}\right)}{\sum_{k=1}^{K}w_{k}\rho_{Z\mid x_{k}}\left(\bar{z}_{j}\right)}\\
 & +\gamma\sum_{j\in J^{-1}\left(k\right)}\frac{\log\left(\sum_{k=1}^{K}w_{k}\rho_{Z\mid x_{k}}\left(\bar{z}_{j}\right)\right)}{\#J^{-1}\left(k\right)}.
\end{align*}

\end_inset


\end_layout

\begin_layout Remark*
Instead of first discretizing and then deriving, one might as well try to
 work with the discretization of the derivative (of the corresponding continuous
 objective).
 Whilst this promises to better approximate the gradient of the underlying
 continuous problem, the gradient does not fit to the objective anymore
 and may therefore lead to problems with optimization routines relying on
 correctness of the gradient.
\end_layout

\begin_layout Subsection
Markov Chain Monte Carlo
\end_layout

\begin_layout Standard
The quality of the Monte Carlo approximations greatly depends on the choice
 of the importance samples 
\begin_inset Formula $\bm{x}$
\end_inset

.
 Whilst an equidistant grid may work well for small dimensional parameter
 spaces 
\begin_inset Formula $\mathcal{X}$
\end_inset

, its number of samples/gridpoints increases exponentially with the dimension
 of 
\begin_inset Formula $\mathcal{X}$
\end_inset

.
 This so called curse of dimensionality suggests the use of Markov Chain
 Monte Carlo (MCMC) sampling, a popular sampling scheme for probability
 densities 
\begin_inset Formula $f$
\end_inset

 defined over high-dimensional spaces.
\end_layout

\begin_layout Standard
The basic idea of MCMC methods revolves around constructing an ergodic Markov
 Chain, a stochastic process whose conditional probability for future states
 depends only on the current state, which has the desired taget density
 
\begin_inset Formula $f$
\end_inset

 as stationary density.
 In the limit of infinite sample sizes the samples from the Markov Chain
 then are distributed according to 
\begin_inset Formula $f$
\end_inset

.
\end_layout

\begin_layout Standard
The probably most common MCMC scheme is the Metropolis–Hastings (MH) algorithm.
 It works by iteratively sampling a proposal 
\begin_inset Formula $x_{n}^{'}\in\mathcal{X}$
\end_inset

 around the last MCMC sample 
\begin_inset Formula $x_{n-1}$
\end_inset

 according to a prescribed p
\emph on
roposal density 
\begin_inset Formula $Q\left(x_{n}^{'}\mid x_{n-1}\right)$
\end_inset

 
\emph default
and accepting or rejecting that proposal in such a way that the resulting
 MCMCs stationary distribution is 
\begin_inset Formula $f.$
\end_inset


\end_layout

\begin_layout Standard
Let us define the corresponding Markoc process in terms of its 
\emph on
transition probabilities 
\begin_inset Formula $P\left(x_{n+1}\mid x_{n}\right)$
\end_inset


\emph default
, starting from the detailed balance condition 
\begin_inset Formula 
\begin{align*}
 & P\left(x'\mid x\right)P\left(x\right)= &  & P\left(x\mid x'\right)P\left(x'\right)\\
\Leftrightarrow & \frac{P\left(x\right)}{P\left(x'\right)}= &  & \frac{P\left(x\mid x'\right)}{P\left(x'\mid x\right)},
\end{align*}

\end_inset

which ensures the existence of a stationary distribution 
\begin_inset Note Note
status open

\begin_layout Plain Layout
ref
\end_layout

\end_inset


\begin_inset Formula $\pi=P\pi$
\end_inset

.
\end_layout

\begin_layout Standard
Taking the Ansatz of splitting the transition probability into a proposal
 distribution 
\begin_inset Formula $g$
\end_inset

 and an acceptance distribution 
\begin_inset Formula $A$
\end_inset


\begin_inset Formula 
\[
P\left(x'\mid x\right)=g\left(x'\mid x\right)A\left(x'\mid x\right),
\]

\end_inset

we end up with 
\begin_inset Formula 
\begin{equation}
\frac{A\left(x'\mid x\right)}{A\left(x\mid x'\right)}=\frac{P\left(x'\right)}{P\left(x\right)}\frac{g\left(x\mid x'\right)}{g\left(x'\mid x\right)}.\label{eq:mhacceptance}
\end{equation}

\end_inset

The Metropolis-Hastings choice for the acceptance distribution 
\begin_inset Formula 
\[
A\left(x'\mid x\right):=\min\left(1,\frac{P\left(x'\right)}{P\left(x\right)}\frac{g\left(x\mid x'\right)}{g\left(x'\mid x\right)}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
satisfies this equation, since either 
\begin_inset Formula $A\left(x'\mid x\right)$
\end_inset

 or 
\begin_inset Formula $A\left(x\mid x'\right)$
\end_inset

 is 
\begin_inset Formula $1$
\end_inset

, while the other equals the desired right hand side of 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:mhacceptance"

\end_inset

.
\end_layout

\begin_layout Standard
This choice allows for the formulation of the following theorem.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $f,g\in\mathcal{M}_{1}\left(\mathcal{X}\right)$
\end_inset

 with 
\begin_inset Formula $f\left(x\right)>0,\,g\left(x\right)>0\,\forall x\in\mathcal{X}$
\end_inset

.
 Then the Markov Process defined by 
\begin_inset Formula 
\[
P\left(x'\mid x\right)=g\left(x'\mid x\right)\min\left(1,\frac{f\left(x'\right)}{f\left(x\right)}\frac{g\left(x\mid x'\right)}{g\left(x'\mid x\right)}\right)
\]

\end_inset

admits 
\begin_inset Formula $f$
\end_inset

 as unique stationary distribution 
\begin_inset Formula 
\[
f=Pf.
\]

\end_inset


\end_layout

\begin_layout Proof
That 
\begin_inset Formula $f$
\end_inset

 indeed is a stationary distribution follows by construction, uniqueness
 follows from irreducibility which is given due to positivity of 
\begin_inset Formula $P$
\end_inset

.
\end_layout

\begin_layout Standard
We hence can use this Markov Process to sample a Markov Chain according
 to the MH-MCMC algorithm:
\end_layout

\begin_layout Enumerate
Start from an arbitrary point 
\begin_inset Formula $x_{0}$
\end_inset


\end_layout

\begin_layout Enumerate
Sample a proposal state 
\begin_inset Formula $x_{n+1}'\sim g\left(x_{n+1}\mid x_{n}\right)$
\end_inset


\end_layout

\begin_layout Enumerate
With probability 
\begin_inset Formula $A\left(x_{n+1}'\mid x_{n}\right)$
\end_inset

 set 
\begin_inset Formula $x_{n+1}:=x_{n+1}'$
\end_inset

, otherwise set 
\begin_inset Formula $x_{n+1}:=x_{n}$
\end_inset


\end_layout

\begin_layout Enumerate
Resume with 2 until sufficient states were generated
\end_layout

\begin_layout Standard
The speed of convergence to the stationary distribution is strongly influenced
 by the choice of the proposal distribution.
 While sampling proposals according to the target distribution would lead
 to the best results, this was not possible firsthand which is why we resorted
 to MCMC.
 A common choice for the proposal distribution is the normal distribution,
 but even here the choice of the covariance is vital for rapid mixing of
 the resulting Markov Chain.
\end_layout

\begin_layout Standard
To circument the obstacle of choosing a proper proposal covariance we decided
 to use the adaptive Metropolis (AM) algorithm by Haario et.
 al 
\begin_inset CommandInset citation
LatexCommand cite
key "haario2001adaptive"

\end_inset

 which tunes the proposal covariance online based on the current samples.
\end_layout

\begin_layout Standard
Specifically we chose the version by Roberts and Rosenthal 
\begin_inset CommandInset citation
LatexCommand cite
key "Roberts2009"

\end_inset

 defining the proposal density as
\begin_inset Formula 
\begin{align*}
g_{n}(\text{·} & \mid x_{n})=\mathcal{N}(x,\,\Sigma_{0}) & \text{if }n\le2d,\\
g_{n}(\text{·} & \mid x_{n})=(1\text{−}β)\mathcal{N}\left(x,\,\frac{2.38^{2}}{d}\Sigma_{n}\right)+β\mathcal{N}(x,\,\Sigma_{0}) & \text{if }n>2d.
\end{align*}

\end_inset

with 
\begin_inset Formula $d$
\end_inset

 beeing the dimensionality of the sampling space 
\begin_inset Formula $\mathcal{X}$
\end_inset

, 
\begin_inset Formula $\frac{2.38^{2}}{d}$
\end_inset

 a scaling constant considered to be optimal for large dimensions 
\begin_inset CommandInset citation
LatexCommand cite
key "roberts1997weak"

\end_inset

.
 
\begin_inset Formula $\Sigma_{n}$
\end_inset

 is the covariance estimate based on the previous samples 
\begin_inset Formula $\left(x_{i}\right)_{i=0}^{n}$
\end_inset

 and 
\begin_inset Formula $\Sigma_{0}$
\end_inset

 an initially chosen positive definite covariance.
 The mixture of the nonrandom normal by 
\begin_inset Formula $\beta>0$
\end_inset

 ensures that the resulting proposal covariance stays positive definite
 even in the case of singular 
\begin_inset Formula $\Sigma_{n}$
\end_inset

.
\end_layout

\begin_layout Standard
The acceptance step remains the same as with the standard MH-MCMC.
 This Markov Chain still admits the desired target density as stationary
 distribution, assuming it is log-concave outside of some arbitrary region
 (for a proof see 
\begin_inset CommandInset citation
LatexCommand cite
key "Roberts2009"

\end_inset

).
\end_layout

\begin_layout Section
Application
\end_layout

\begin_layout Standard
We will now discuss the application of the developed empirical Bayes method
 on the basis of a large-dimensional ordinary differential model accompanied
 by real-life measurements.
 We will therefore introduce the model and perform a standard Bayesian posterior
 inference as starting point for the prior estimation by means of MCMC sampling.
 We will then compute the MLE, MPLE and DS-MLE prior estimates and discuss
 the results.
\end_layout

\begin_layout Subsection
The problem
\end_layout

\begin_layout Standard
Our physical model, consisting of a system of 33 ordinary differential equations
, models the feedback mechanisms of the prevalent hormones in the female
 menstrual cycle with a focus on GnRH-receptor binding and was derived by
 Röblitz et al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "roblitz2013"

\end_inset

.
 For the equations we refer to the original paper.
\end_layout

\begin_layout Standard
This system is parametrized by 114 parameters, out of which 21 (the Hill
 parameters) are considered fixed for the following survey.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "roblitz2013"

\end_inset

 the authors furthermore computed point estimates for the parameters and
 initial conditions.
 We will denote these as 
\emph on
nominal parameters 
\begin_inset Formula $\theta^{\text{nom}}$
\end_inset

 
\emph default
and 
\emph on
initial conditions
\emph default
 
\begin_inset Formula $y_{0}^{nom}$
\end_inset

 and use them as initial conditions for the Markov chain as well as for
 the prior computation.
\end_layout

\begin_layout Standard
Let us denote its solution at time 
\begin_inset Formula $t$
\end_inset

 with parameters 
\begin_inset Formula $\theta\in\mathbb{R}^{82}$
\end_inset

 and initial conditions 
\begin_inset Formula $y_{0}\in\mathbb{R}^{33}$
\end_inset

 as
\begin_inset Formula 
\[
\phi\left(t;\theta,y_{0}\right)\in\mathbb{R}^{33}.
\]

\end_inset


\end_layout

\begin_layout Standard
Our data consists of blood concentrations of follicle-stimulating hormone
 (FSH), luteinizing hormone (LH), estradiol (E2) and progesterone (P4) measured
 from 45 healthy women over thirty days, roughly every second day.
 This data was collected in the context of PAEON, a collaborative European
 research project on eHealth.
 Denote the set of measurements for a single patient 
\begin_inset Formula $m$
\end_inset


\begin_inset Formula 
\[
z^{m}:=\left(z_{t,i}^{m}\right)_{\left(t,i\right)\in I_{z}^{m}}
\]

\end_inset

 with 
\begin_inset Formula $z_{t,i}^{m}$
\end_inset

 beeing the single measurement of species 
\begin_inset Formula $i=1,...,4$
\end_inset

 at time 
\begin_inset Formula $t$
\end_inset

 and 
\begin_inset Formula $I_{z}^{m}$
\end_inset

 denoting the index set of available measurements.
\end_layout

\begin_layout Standard
To impose the condition of periodicity of the data onto our inference process
 we further augment the data by a copy of itself shifted in time by an additiona
l latent parameter representing the period length 
\begin_inset Formula $\tau$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
z^{m,\tau}:=\left(\hat{z}_{t,i}^{m}\right)_{\left(t,i\right)\in I_{z}^{m,\tau}},
\]

\end_inset

with augmented index set 
\begin_inset Formula 
\[
I_{z}^{m,\tau}=\bigcup_{\left(t,i\in I_{z}^{m}\right)}\left\{ \left(t,i\right),\left(t+\tau,i\right)\right\} 
\]

\end_inset

 and augmented measurements
\begin_inset Formula 
\[
\hat{z}_{t,i}^{m}:=\begin{cases}
z_{t,i}^{m} & \text{if }\left(t,i\right)\in I_{z}^{m}\\
z_{t-\tau,i}^{m} & \text{otherwise}
\end{cases}.
\]

\end_inset

 
\end_layout

\begin_layout Standard
Subsuming the latent model parameters 
\begin_inset Formula $\theta$
\end_inset

 (
\begin_inset Formula $82)$
\end_inset

, the initial conditions 
\begin_inset Formula $y_{0}$
\end_inset

 
\begin_inset Formula $(33)$
\end_inset

 and the period length 
\begin_inset Formula $\tau$
\end_inset

 we end up with 116 parameters 
\begin_inset Formula $x=\left(\theta,y_{0},\tau\right)$
\end_inset

for the Bayesian inference.
\end_layout

\begin_layout Standard
We model each single measurement as independent on the others and afflicted
 by a Gaussian measurement error with independent componentwise standard
 deviations of 
\begin_inset Formula $10\%$
\end_inset

 of their respective order of magnitude, estimated from the nominal solution
 
\begin_inset Formula $\phi^{nom}\left(t\right):=\phi\left(t;y_{0}^{\text{nom}},\theta^{\text{nom}}\right)$
\end_inset

:
\begin_inset Formula 
\[
\sigma_{1}^{\text{meas}}=12,\,\sigma_{2}^{\text{meas}}=1{}^{2},\,\sigma_{3}^{\text{meas}}=40^{2},\,\sigma_{4}^{\text{meas}}=1.5^{2}.
\]

\end_inset

 We end up with the following likelihood function for the parameters 
\begin_inset Formula $x$
\end_inset

 given a single persons data 
\begin_inset Formula $z^{m}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
L\left(x\mid z^{m}\right)=L\left(\theta,y_{0},\tau\mid z^{m}\right)=\left(\prod_{\left(t,i\right)\in I_{z}^{m,\tau}}\frac{1}{\sigma_{i}^{\text{meas}}\sqrt{2\pi}}\right)\exp\left(-\frac{1}{2}\sum_{\left(t,i\right)\in I_{z}^{m,\tau}}\left(\frac{\phi\left(t;\theta,y_{0}\right)_{i}-z_{t,i}^{m,\tau}}{\sigma_{i}^{\text{meas}}}\right)^{2}\right).
\]

\end_inset


\end_layout

\begin_layout Remark
This likelihood correctly reflects the amount of information available dependent
 on the number of measurements.
 A higher number of measurements results in sharper specified likelihood
 function.
 This will allow us to correctly treat different patients/measurements together
 in the upcomming empirical Bayes analysis.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Remark
One might argue that this model manipulates the data and hence is no more
 of the form 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:gaussmodel"

\end_inset

.
 But it is equivalent to the model obtained but just duplicating the data
 and subsuming the shift operation into a new forward solution operator,
 hence 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:addmeastheo"

\end_inset

 still applies.
\end_layout

\begin_layout Remark
For the initial Bayesian sampling procedure, necessary for arrival at a
 discretization of 
\begin_inset Formula $\mathcal{X}$
\end_inset

, we furthermore need to specify the priors to our parameters.
\end_layout

\begin_layout Remark
For we did not want to imply any knowlege on 
\begin_inset Formula $\theta$
\end_inset

 but their order of magnitude we chose the uniform prior bounded by the
 
\begin_inset Formula $\alpha:=5$
\end_inset

 multiple of its corresponding nominal parameter
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(\theta_{i}\right)=\pi_{i}=\mathcal{U}\left(0,\alpha\theta_{i}^{\text{nom}}\right)\quad i=1,...,82.
\]

\end_inset


\end_layout

\begin_layout Standard
The prior for the initial conditions 
\begin_inset Formula $y_{0,i}=\theta_{82+i},\,i=1,...,33$
\end_inset

 is constructed as a mixture of Gaussians centered at the trajectories of
 the nominal solution
\begin_inset Formula 
\[
P\left(\theta_{82+i}\right):=\frac{1}{31}\sum_{t=0}^{30}\mathcal{N}\left(\phi^{\text{nom}}\left(t\right),\,\Sigma\right)\quad i=1,...,33
\]

\end_inset

and the covariance 
\begin_inset Formula $\Sigma$
\end_inset

 beeing a diagonal matrix with the component-wise covariance estimates
\begin_inset Formula 
\[
\Sigma_{ii}:=\text{Cov}\left(\left(\phi_{i}^{\text{nom}}\left(t\right)\right)_{t=0}^{30}\right),\quad i=1,...,33.
\]

\end_inset


\end_layout

\begin_layout Standard
The prior for the period length 
\begin_inset Formula $\theta_{116}$
\end_inset

 was chosen to be Gaussian with mean 28.9 days and a standard deviation of
 3.4 days (c.f.
 
\begin_inset CommandInset citation
LatexCommand cite
key "fehring2006variability"

\end_inset

) 
\begin_inset Formula 
\[
P\left(\theta_{116}\right)=\mathcal{N}\left(28.9,3.4^{2}\right).
\]

\end_inset


\end_layout

\begin_layout Subsection
Sampling
\end_layout

\begin_layout Standard
We will now compute the individual posterior samples
\begin_inset Formula 
\[
\left(x_{i}^{m}\right)\sim\rho_{x\mid z^{m}}L\left(\theta\mid z\right)\rho_{z}^{0}\left(z\right)
\]

\end_inset

for each patient 
\begin_inset Formula $m$
\end_inset

.
\end_layout

\begin_layout Standard
Since all sampled parameters 
\begin_inset Formula $\left(\theta_{i}\right)_{i=1}^{116}$
\end_inset

 are restricted to 
\begin_inset Formula $\mathbb{R}^{+}$
\end_inset

 but the used AM sampler uses normal proposal densities with global support,
 we first rescale the original parameters using 
\begin_inset Formula $\log:\mathbb{R}^{+}\rightarrow\mathbb{R}$
\end_inset

:
\begin_inset Formula 
\[
\tilde{\Theta}_{i}=\log\left(\Theta_{i}\right),\quad i=1,...,116.
\]

\end_inset

The normal proposals in the log-space now correspond to lognormal proposals
 in the original parameter space.
\end_layout

\begin_layout Standard
however undergoing this transformation we also have to adjust the likelihood
 function according to the change of variables formula:
\begin_inset Formula 
\[
\tilde{L}\left(\tilde{\theta}\mid z\right)=L\left(\exp\left(\tilde{\theta}\right)\mid z\right)\prod_{i=1}^{116}\tilde{\theta}_{i}
\]

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
find correct transformation
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Chosing the initial value for the Markov chain according to our nominal
 values 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{alignat*}{2}
x_{0,i} & :=\log\theta_{i}^{\text{nom }}, &  & \quad i=1,..,82\\
x_{0,82+i} & :=\log y_{0,i}^{\text{nom}}, &  & \quad i=1,..,33\\
x_{0,116} & :=\log28.9,
\end{alignat*}

\end_inset


\end_layout

\begin_layout Standard
we may hope to start in a region of high density which henceforth is already
 representative for the target density and thus expect a relatively short
 burnin phase.
\end_layout

\begin_layout Standard
In the first runs the initial covariance 
\begin_inset Formula $\Sigma_{0}$
\end_inset

 of the proposal density for the AM sampler was chosen to be uniform.
 Upon later runs we reused the covariance structure 
\begin_inset Formula $\Sigma_{N}$
\end_inset

 of present samplings according to
\begin_inset Formula 
\[
\Sigma_{0}:=\frac{2.38^{2}}{d}\Sigma_{n},
\]

\end_inset

to speed up the adaption process.
\end_layout

\begin_layout Standard
We computed 
\begin_inset Formula $50.000.000$
\end_inset

 samples 
\begin_inset Formula $\bm{x}^{m}$
\end_inset

 for each patient 
\begin_inset Formula $m$
\end_inset

 at an average speed of around one million samples per hour and core.
 
\end_layout

\begin_layout Standard
Convergence tests / burnin/thinning
\end_layout

\begin_layout Standard
plot mcmc chain
\end_layout

\begin_layout Standard
Let us denote the thinned and burnin-rectified samplings for each person
 
\begin_inset Formula $m$
\end_inset

 by 
\begin_inset Formula $\bm{x}^{m}$
\end_inset

.
\end_layout

\begin_layout Subsection
Prior estimation
\end_layout

\begin_layout Standard
Given the individual patients posterior samples 
\begin_inset Formula $\left(\bm{x}^{m}\right)_{m=1}^{53}$
\end_inset

 we combine these in order to obtain a basis for the prior estimation.
 
\begin_inset Formula 
\[
\bm{x}^{M}=\bigcup_{m=1}^{M}\bm{x}^{m}.
\]

\end_inset

Note that these samples, which conform to the average density of the individual
 posteriors, are 
\begin_inset Formula $\psi\left(\pi_{0}\right)$
\end_inset

 distributed.
 Our experiments have shown that this first approximation step is already
 quite close to the ML estimate.
 Putting mass at points of igh likelihood one can hence hope that they serve
 as a good basis for the importance sampling procedures involved in the
 prior estimations.
\end_layout

\begin_layout Subsection
Results
\end_layout

\begin_layout Standard
paperplot
\end_layout

\begin_layout Standard
2d marginals?
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "refs"
options "plain"

\end_inset


\end_layout

\begin_layout Section*
Appendix
\end_layout

\begin_layout Subsection*
Implementation
\end_layout

\begin_layout Standard
The introduced algorithms were implemented Julia, a modern programming language
 for numerical computing and bundled in the open-source package GynC.jl,
 available at www.github.com/axsk/GynC.jl.
\end_layout

\begin_layout Standard
In the following we will give an overview over the core components of the
 software and discuss some implementation details.
\end_layout

\begin_layout Subsubsection*
Empirical Bayes - src/eb
\end_layout

\begin_layout Subsubsection*
GynC - src/gc
\end_layout

\end_body
\end_document
